# Hidden Technical Debt in Machine Learning Systems 
* author : D. Sculley of Google.Inc
* society: NIPS(Neural Information Processing Systems)
* date : 2015
* link : [[pdf]](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)
---

### Abstract 
머신러닝은 복잡한 예측 시스템을 위한 강력한 도구를 빠르게 제공한다. 본 논문은 이런 빠른 승리들이 
무상으로 제공된다고 생각하는 것은 위험한 생각이라고 주장한다. Software Engineering의 기술부채(technical debt) 프레임워크를 활용하여, 
현실속의 머신러닝 시스템에서 계속되는 엄청난 유지보수 비용을 발생시키는 것이 흔한 일임을 알 수 있다. 
여러가지 ML-specific 리스크 요소들을 탐색하여 시스템 디자인에 고려하고자한다. 이러한 요소들에는 
경계침식 (boundary erosion), entanglement, hidden feedback loops, undeclared consumers, data dependencies, 
configuration issues, changes in the external world, 다양한 시스템 레벨의 anti-patterns가 있다.

---
### Summary
#### Introduction 
머신러닝이 발전하면서 불편한 트렌드가 널리 확산되기 시작했다. 머신러닝 시스템의 개발과 배포는 상대적으로 빠르고 저렴해졌다, 
하지만 유지보수가 어려워지고 비용이 증가했다. 이러한 이분법적인 현상은 기술부채의 관점에서 설명될 수 있다. 
재정 부채와 마찬가지로 기술 부채를 떠안아야 할 정상적이고 전략적인 상황들이 분명 존재한다. 모든 부채가 나쁜 것은 아니지만 
결국은 상환되어야한다. 기술 부채는 코드 리팩토링 그리고 유닛 테스트 개선, 데드 코드 제거, 의존성 감소, API 축소, 
다큐멘테이션 개선을 통해 상환될 수 있다. 새로운 기능을 추가시키는 것을 목표로 두는 것이 아닌, 발전 가능성 확대, 오류 감소 
그리고 유지 보수성을 개선시키기 위함이다. 숨겨진 부채는 조용히 쌓이기 때문에 상환을 미루는 행위는 비용 축적을 불러온다. 

머신러닝 시스템은 전통적인 소프트웨어가 가진 부채 발생 가능성 외의 추가적인 가능성이 존재한다. 기존 소프트웨어의 부채 발생 가능성을 
모두 갖고있으면서 머신러닝 특화된 문제가 있다. 이러한 부채는 코드 레벨이 아닌 시스템 레벨에 존재하기 때문에 알아 차리기 힘들다. 
전통적인 추상화 경계가 머신러닝 시스템에서는, 외부 데이터의 영향으로 희미해지거나 허물어 질 수 있다. 코드 레벨에서의 노력은 머신러닝 
시스템 레벨에서 발생하는 부채를 상환하기에 충분하지 않다. 

> 머신러닝 시스템에서 발생하는 부채는 전통적인 소프트웨어에서 발생하는 부채 + 머신러닝 시스템에서만 발생하는 부채로 이루어져 있다. <br>
> 머신러닝 부채는 시스템 레벨에 존재하기 때문에, 코드 레벨에서 상환 할 수 없다. 
> 상환 계획 없이 놔두면, 알아차리지 못하는 상태로 빠르게 축적된다. 


#### 1 복잡한 모델은 경계를 침식 시킨다 
전통적인 Software Engineering에서 캡슐화(encapsulation)와 모듈설계(module Design)를 통해 강한 추상화 경계(Strong abstraction boundaries)를 
만든다. 이 경계를 통해 독립된 환경을 만들고 유지보수가 가능하도록 복잡한 코드를 설계할 수 있다. 강한 추상화 경계를 통해 해당
컴포넌트의 입력값과 출력값에 대해 논리적 일관성(logical consistency)과 불변성(invariants)를 구현했다. 하지만 Machine Learning 시스템은 
외부 데이터에 의존하지 않고 소프트웨어 로직으로만 구현이 불가능하기 때문에 해당.

> 외부데이터의 유입으로 "강한 추상화 경계"가 무너지기 때문에 기술부채가 쌓이게 된다. 

##### 1.1 Entanglement(얽힘)
머신러닝 시스템은 시그널이 섞이게 되어, 독립적인 시스템의 발전이 불가능하게 한다. 한 모델에서
여러개의 기능이 있는데 그중 하나를 바꾸게 하려고 해도 나머지 기능들에 모두 영향을 끼치게 된다. 
기능을 추가하거나 제가하는 행동에도 유사한 현상이 일어날 수 있다. 한 input은 절대로 완전히 독립적일 수 없다.
이러한 현상은 CACE 이론으로 설명 될 수 있다. Changing Anything Changes Everything. 이는 input signal에만 
국한 된 것이 아니라, hyper-parameter, 학습 환경, 샘플링 방법론, 수렴 임계치, 데이터 선정 그리고 
다른 모든 설정 가능 값들에 해당된다. 

다음은 얽힘의 정도를 줄일 수 있는 방법 두가지를 소개하겠다. 
- Mitigation Strategy 1 : 모델을 독립시키고 앙상블을 사용하라. <br>
본 접근은 disjoint multi-class settings와 같이 sub-problem이 자연스럽게 나뉘어 지는 상황에서 권장된다. 
- Mitigation Strategy 2 : 예측 행동의 변화 발생과 동시에 감지 <br>
리서처들이 여러 차원과 slicing을 빠르게 보기 위해서 사용된 고차원 시각화 툴을 사용할 때 고안되었다.  
Slice-by-slice로 운용되는 metric에서 매우 유용하다. 

##### 1.2 Correction Cascades (지속적 보정)  ** non-tech 언어로 수정 필요 **
A라는 문제를 해결하기 위한 m(a)라는 모델에서 약간 다른 A'에 해당되는 솔루션이 필요한 경우가 있다. 이러한 경우에
m(a)를 input으로 갖고 사소한 수정 사항들을 학습하는 방식으로 m'(a) 모델에 대하여 학습해야 해답으로 가는 빠른 
방법이라고 생각하기 쉽다 생각하기 쉽다. 하지만 이러한 correction 모델은 m(a) 모델에 대한 의존성을 만들어 
결국 미래에 성능 향상을 위해서 훨신 높은 비용이 들도록 만든다. A'' 의 문제를 해결하기 위해 
m'(a)를 학습하는 방향으로 지속적인 보정이 일어나면 그 비용은 상승한다. 지속적 보정은 개선 교착 상태를 
만들어 낼 수 있다. 한 요소의 정확도를 높이는 노력이 시스템 레벨에서의 악영향을 불러올 수 있기 때문이다. 
이러한 문제를 줄이는 mitigation strategy는 해당 모델에서 correction을 학습하고 추가적인 문제를 해결하기 위해서
새로운 feature를 추가해나가거나, 문제 해결을 위해 새로운 모델을 만드는 것에 대한 비용을 받아들이는 것이다.  

##### 1.3 Undeclared Consumers (미신고 고객) 
ML 모델에서의 예측은 실시간으로 혹은 로그파일에 기록된다. 그 로그 파일을 input으로 받아 다른 시스템에서
활용 될 수 있다 (pipeline 앞단의 output이 뒷단의 input이 되는 케이스). 이런 경우를 전통적인 
software engineering에서는 가시성 부채 (visibility debt)이라고 부른다. 시스템을 사용하는 고객 중 일부는
미신고 고객이 되어서 조용하게 다른 시스템의 입력값으로 사용된다. 신고가 되지 않은 고객은 시스템의
다른 모델에 숨겨진 타이트한 결합 (hidden tight coupling of model)이 되어 최고로 비싸며, 최악의 경우
위험 할수도 있다. 모델을 수정할 경우 결과에 대한 이해가 부족해지고 다른 부부에 영향을 미칩니다. 
또한, 미신고 고객은 숨겨진 피드백 루프를 만들어 낼 수도 있다. 

#### 2 데이터 의존성은 코드 의존성보다 비싸다 
의존성 부채는 전통적인 소프트웨어 엔지니어링 관점의 코드 복잡성과 기술 부채의 주요 요인으로 언급된다. 머신러닝 환경에서의 
데이터 의존성은 전통적인 소프트웨어와 비슷하게 부채 발생 가능성이 있지만 훨신 감지하기 어렵다. 코드 의존성은 compiler와 
linker를 통한 static analysis로 감지 될 수 있지만, 데이터 의존성 감지를 위한 유사한 도구는 존재하지 않는다. 그러므로
해소하기 힘들고 만들기는 쉬운 거대한 데이터 의존성을 키우는 행동은 부적절하다. 

##### 2.1 불안정한 데이터 의존성 
빠른 작업을 위해서 다른 시스템에서 이미 만들어진 시그널을 feature로 사용하면 편리하다. 하지만,
몇몇 시그널은 정량적/정성적으로 시간의 흐름에 따라 다른 행동을 보이는 형태의 불안정성을 보인다. 이러한 불안정성은 
내재적으로 일어나기 때문에 감지하기 힘들다. 예를 들어, input signal이 스스로 업데이트 되는 
다른 ML모델로 부터 오거나, TF/IDF스코나 semantic mapping같은 데이터 의존적인 lookup 테이블과 같은 경우가 있다. 
가시적으로 나타나는 불안정성도 존재한다. 모델에 대한 engineering ownership과 input data에 대한 ownership이 다른경우 
발생한다. 이러한 케이스에서는 언제든 input signal의 업데이트가 이루어질 수 있다. Input signal을 개선하는 것 조차
시스템에 악영향을 미칠 수 있다는 점이 위험하게 만든다. 이러한 문제는 진단과 감지하는 비용이 높다. 예를 들어, 
input signal이 잘못 calibrate 되었다고 가정했을때, 그 signal을 사용하는 모델은 잘못 calibrate된 input에 대하여
fitting을 하게된다. 이러한 signal 문제를 해결하기 위한 업데이트는 여러가지 다른 문제를 발생 시킬 수 있다.

흔하게 사용되는 불안정한 데이터 의존성을 해소하기 위한 migration strategy는 여러 버전의 시그널을 백업해두는 것이다.
예를 들어, 단어들의 semantic mapping이나 topic cluster를 시간의 흐름에 따라 변화하게 두는 대신 단일 시간의 
frozen 버전의 mapping을 업데이트 된 버전이 검증되기 전까지 활용하는 형태로 사용한다. 여러 version을 저장해두는
행위 자체가 비용을 만들기도한다. 

##### 2.2 활용도 낮은 데이터 의존성 
상당 부분의 기능을 사용하지 않는 패키지를 일컫는 말이다. 모델 개선을 위해 아주 작은 기여를 하는 
input signal인데, 지워도 아무 문제가 없음에도 불구하고 때때로 굉장히 심각 할 수 있는 변화에 대한 
취약성을 만들어 낼 수 있다. 예를 들어, 기존 제품 번호 scheme에서 새로운 버전으로 이동하는 과정을 
쉽게 만들기 위해 두 scheme의 feature가 모두 남아있게 된다. 새로운 제품에 대해서는 새로운 버전으로 
기록하게 되고 기존에 있던 제품은 계속해서 기존 scheme에 의존하게된다. 1년 후, 기존의 제품 번호로 
데이터베이스를 채워넣던 코드는 삭제되는 문제가 발생한다. 활용도 낮은 데이터 의존성은 다음과 
같은 여러가지 형태로 존재한다 : 
###### 2.2.1 legacy features 
모델 개발의 초기 단계에 있었던 기능이 더 개선된 형태로 새로 개발이 되었지만 중복되는 기존의 기능이 삭제되지 않은 케이스
###### 2.2.2 bundled features 
유사한 기능을 하는 여러 기능들이 하나의 모델안에 혼재하는 케이스
###### 2.2.3 epsilon features
복잡성이 높아지는 것에 비해 모델 정확도가 높아지지 않더라도 사소한 개선을 위해 복잡성을 희생하도록 하는 케이스
###### 2.2.4 correlated features
유사성이 있는 두 모델 중, 어떤 모델이 인과성을 갖는지 정확한 판단이 안된 케이스. 두 기능이 동일한 수준으로 
취급되거나, 인과성이 낮은 모델이 고평가 받는 경우이다. 이러한 현상은 software brittleness를 야기 할 수 있다. 

##### 2.3 Static Analysis of Data Dependencies 
전통적인 코드에서는 컴파일러와 빌드 시스템이 의존성 그래프에 대한 static analysis를 하도록 한다.
데이터 의존성 static analysis를 위한 툴은 흔하지는 않지만 error checking과 고객추적 그리고 migration 및 update를 
진행하기 위해서 필수적이다. 이러한 툴 중 하나는 자동화 된 feature management 시스템이다.
이 시스템은 데이터 소스와 feature가 annotate되어 있는지 확인 가능하다. 자동화된 검증은 모든 의존성이 
적절한 annotation이 있는지 확인 할 수 있게하고 의존성 tree가 해결 될 수 있도록한다. 이러한 툴 사용은 migration과 
삭제작업을 안전하게 만든다. 
  
![20200311_162316](https://user-images.githubusercontent.com/60588476/76392339-b038d880-63b4-11ea-9f4e-fd4a91cdb394.png)
> 위 이미지에서 확인 할 수 있듯, ML Code 자체는 전체 시스템에서 생각보다 큰 부분을 차지하지 않는다. 

#### 3 피드백 루프 
라이브 머신러닝 시스템의 핵심 기능 중 하나는, 발전되는 흐름에 따라 대상 모델이 모델 자신의 행동에 영향을 미친다는 것이다. 
이것을 분석 부채(Analysis Debt)라고 하는데, 행동에 따란 다른 현상을 보이기 때문에 배포하기 전까지 모델의 행동을
예측하기 힘들다. 이런 피드백 루프는 여러 형태로 진행될 수 있으고, 모델이 자주 업데이트 되지 않아 점진적으로 진행되므로 
탐지하기 어렵다.  

##### 3.1 직접적인 피드백 루프 (direct feedback loops) 
모델이 미래에 사용될 학습 데이터 선택에 직접적으로 영향을 끼치는 것을 해결하기 위해 bandit algorithm을 사용해야하지만,
일반적으로 supervised algorithm을 사용한다. 여기서 bandit algorithm은 일반적으로 현실 문제 해결에 필요한 
동작 공간의 크기에 맞게 확장되지 않는 것이 문제이다. 이것을 해결하기 위해 randomization을 사용하거나,
주어진 모델로 부터 영향을 받지 않도록 데이터의 특정 부분을 분리한다.

##### 3.2 숨겨진 피드백 루프 (hidden feedback loops) 
직접적인 피드백 루프는 머신러닝 연구자가 찾은 통계학적 접근에 집중하고 분석 비용이 높다. 
숨겨진 피드백 루프는 두개의 시스템이 상호 간접적으로 영향을 미치는 경우를 의미한다.
예를 들면, 웹페이지를 표시할 제품을 선택하는 부분과 관련 리뷰를 선택하는 부분이 있다고
가정 할 때, 한 시스템을 개선하면 사용자가 변경 사항에 반응해 다른 요소를 더 많이
혹은 덜 클릭해 시스템 동작이 변경될 수 있다. 이러한 숨겨진 루프는 완벽히 분리된 
시스템에서도 존재 할 수 있다. 두 투자회사에서 사용하는 두가지 주식시장 예측 모델을 고려해보자.
한 모델에서의 개선 사항(버그 해결을 포함한)이 다른 모델의 입찰과 매수 행동에 영향을 줄 수 있다. 


#### 4 ML 시스템의 안티 패턴 anti-patterns-system anti-patterns [[안티 패턴 참고]](https://ukzzang.tistory.com/18)
##### 4.1 접착제 코드 (glue code) 
오픈소스 라이브러리를 사용 할 경우, 일반적으로 접착제 코드 시스템 디자인 패턴 (Glue code
system design pattern)으로 귀결된다 당장은 문제가 없지만 장기적으로 기술부채 문제를 
야기할 수 있다. 우리가 라이브러리에서 사용하는 부분은 작은 부분인데, 그 부분에 변화가
일어났을 때, 우리의 코드도 수정해야하는 상황이 발생한다. 또한, 범용 머신러닝 시스템은
많은 문제를 해결하는데 초점을 맞춘 반면, 실무에 적용된 시스템은 한 문제에 대해 확장성이
크게 개발되는 경향이 있기 때문에 딜레마가 생기곤 한다. 
Glue code를 해결하기 위해서 black-box 패키지들을 common API로 묶어버리는 방법이 있다. 이러한 방법은 
뒷받침하는 기반이 재사용하기 용이하록 만들고 패키지를 바꾸는 작업에 대한 비용을 낮출 수 있게한다.


##### 4.2 파이프라인 정글 (pipeline jungles) 
파이프라인 정글은 접착제 코드의 특수 케이스인데, 보통 데이터 준비 단계에서 볼 수 있다. 
이러한 문제는 새로운 signal이 생기거나 새로운 정보 source가 추가되었을 경우 스스로 발생 할 수 있다. 
신경을 쓰지 않으면 ML에 적합한 데이터 준비 과정이 아니라 데이터 추출, join, 샘플링 등의 과정이 뒤죽박죽이 될 수 있다.
이러한 pipeline을 관리하고, error를 감지하고, failure를 해결하는 것은 어렵고 비싸다. 이러한 pipeline을 테스팅 하는 과정은 
고비용의  end-to-end integration test가 필요하다. 이 모든 과정은 기술부채로 들어가게되고 추가적인 혁신을 어렵게 만든다. 
파이프라인 정글을 방지하는 유일한 방법은 데이터 수집과 feature extraction을 통합적으로 고려하는 것이다. 
Research와 engineering의 격차가 만들어내는 통합 이슈이다. ML 패키지가 복잡하게 개발이 된다면 사용자 입장에서는 
blackbox처럼 보이게 된다. Researcher와 engineer가 함께 리서치하는 접근은 마찰을 현저하게 줄일 수 있게 한다.  
 
##### 4.3 죽은 실험 코드 경로
실제 운영중인 코드에 추가로 branch를 생성해 기능들을 테스트하는 것은 여러가지 방법론을 단기에 테스트 할 수 있도록한다. 
개별적인 변화를 위해 실험 코드를 생성하는 것은 적은 비용으로 테스트 할 수 있게한다. 하지만, 이러한 코드들이 
계속해서 축적된다면 backword compatibility 유지보수 난이도 상승과 cyclomatic complexity로 인해 부채가 커지게 된다.
주기적으로 실험 코드 branch를 재검토하면서 삭제해도 되는 부분을 찾아내는 과정이 필요하다. 
대개 test branch의 일부분만이 실제로 사용되고 나머지 부분들은 한두번 테스팅되고 버려지는 코드들이 많다.

##### 4.4 추상화 부채 (abstraction debt)
위의 이슈들은 모두 머신러닝 시스템을 지원할 강한 추상성이 부족하단 사실을 강조한다. 관계형 데이터베이스에 비해서
데이터 스트리밍, 모델 또는 예측을 설명하는 인터페이스가 존재하지 않아서 추상화가 더욱 필요하다. 특히 분산학습의 경우 
Map-Reduce가 널리 사용되는 이유는 강력한 분산학습 추상화가 없기 때문이다. Map-Reduce는 반복적인 머신러닝 알고리즘의 빈약한 추상이다. 

##### 4.5 일반적인 문제 (common smells) * Smell : 시스템 혹은 컴포넌트 상에 내재되어있는 문제
ML 시스템의 문제를 찾아내기 위한 주관적인 지표들을 다음과 같이 제시한다 : 
##### 4.5.1 plain-old-data type smell
ML시스템에서 사용되고 만들어진 정보는 보통 integer, float과 같은 plain type으로 encoding 되어있는 경우가 많다. 
건강한 시스템에서는 이러한 model parameter가 log-odds multiplier인지 의사결정 임계치인지 판별해야하고,
prediction은 어떤한 모델이 예측을 했는지와 어떻게 사용되어야 하는지 알아야한다. 

##### 4.5.2 multiple-language smell
시스템의 한 부분에서 특정 언어로 만들기 쉬운 부분들이 있다. 문제 해결을 위한 library가 존재한다던가, syntax가 쉽다는 등의 
이유로 하나의 시스템에서 여러가지 언어를 사용하게 되기 쉬운데, 이러한 multi-language 문제는 유지보수 차원에서 
효율적인 테스팅과 소유권 이전 작업에서 높은 비용을 발생시킨다.

##### 4.5.3 prototype smell 
프로토타입을 통해 사소한 아이디어를 테스팅하기 용이하다. 하지만 과도하게 프로토타이핑 환경에 의존하는것은 full-scale 
scope에서 다루기 힘들고, 수정이 어렵다. 발전된 형태의 interface나 개선된 추상화로부터 이득을 취할 수 있을 것이다.
프로토타이핑 환경을 유지하는 것은 그 자체로도 비용을 발생시키고, 시간제한 같은 문제가 닥쳤을 때,
프로토타입을 실제 production solution으로 활용하는 참사를 부추길 수 있다. 이러한 작은 스케일은 full scale을 대변 할 수
있는 경우가 거의 존재하지 않는다.

#### 5 설정 부채 (Configuration Debt) 
큰 규모의 시스템은 기능 선정, 데이터 선정, 특정 알고리즘의 초기 설정, 선/후처리 가능성, 
검증 방법 등 수많은 설정값들이 존재한다. 리서처와 엔지니어 모두 설정 값이 그렇게 중요하다고
생각하지 않을 수도 있지만, 때때로는 모델을 만드는 코드보다 configuration을 만다는 
코드 라인이 더 길 경우도 있고 그만큼 실수가 발생 할 수 있는 가능성이 있다. 
 
좋은 configuration system은 다음과 같다 :  
* 이전 버전으로 부터의 변화를 쉽게 찾을 수 있는 configuration
* 매뉴얼 error, ommisions, oversights가 발생하기 어려워야 한다. 
* 두 모델 사이의 환경 설정 차이에 대해 쉽게 시각적으로 볼 수 있어야한다.
* 설정에 따른 기본적인 팩트를 검증하는 것이 쉬워야한다 : 사용된 feature 수, 데이터 의존성 등
* 미사용/중복 설정 값을 감지 할 수 있어야 합니다.
* 환경 설정은 전체 코드 검토로 진행되고 repository로 checkin 되어야 한다. 

#### 6 외부 변화 대응 
외부 세계와 직접적으로 교류한다는 점이 ML 시스템을 매력적으로 만든다. 우리는 경험으로부터 
외부 세계가 안정적인 경우는 극히 드물다는 것을 알고있다. 이러한 백그라운드의 변동률은 
지속적인 유지보수 비용을 발생시킨다.  

##### 6.1 동역학계(dynamic system)에서의 고정 임계치 설정 
모델이 역할을 수행하기 위해 의사결정 임계치를 설정하는 것이 필수적이다 : 참/거짓 예측, 이메일 spam/ non-spam 판별,
광고 노출 여부. ML에서의 일반적인 접근은 precision이나 recall과 같은 특정 metric에서의 적절한 tradeoff를 
설정하기 위해 여러 입계치의 집합 중에서 임계치를 설정하는 것이다. 하지만, 이러한 임계치는 대개 수동으로 설정된다. 
그러므로 모델이 새로운 데이터로 업데이트가 된다면 기존에 설정되어 있던 임계치는 무의미해질 수 있다. 여러 모델에서
임계치를 수동으로 계속해서 설정하는 행동은 시간낭비이고 다루기 힘들다. 이러한 문제에 대한 mitigation strategy는 
따로 떼어 놓은 validation data를 기준으로 임계치를 학습시켜서 해결하는 것이다. 

> 임계치 설정을 수동으로 하면 데이터의 변화가 생길 때마다 새로 설정해야하는 문제가 있으므로
> validation data를 기준으로 임계치를 학습시키는 방향으로 자동화 되어야한다. 

##### 6.2 모니터링과 테스팅
소프트웨어 시스템에서는 unit test와 통합 테스트를 하는것도 필요하지만, 머신러닝 시스템은 예측력과 해당 시스템이 
취하는 동작에 대한 모니터링이 필요하다. 그 전에 "무엇을 모니터링 할것인가"에 대한 주요 질문을 생각해야 함. 
머신러닝 시스템에서 실험 가능한 변수가 명백하게 알 수 없을 경우도 있기 때문에 해당 질문에 대한 생각을 해봐야하고
그 후, 다음과 같은 항목에대한 고려도 되어야 함. 
#### 6.2.1 prediction bias (편향 예측)
머신러닝 시스템이 의도한 대로 움직이는가? 
#### 6.2.2 action limits
원치않는 상황이 발생할 경우 경고 시그널을 주거나 수동으로 전환이 쉬워야함.
#### 6.2.3 up-stream producers 
업스트림 프로세스를 모니터 할 수있어야 한다. 어디서 failure가 발생했는지와 이후 작업 진행 여부 등 확인 가능 해야함. 

> 소프트웨어 엔지니어링에서 unit test 및 통합 테스트가 중요하듯, 머신 러닝에서는 예측과 진행 상황에 대한 모니터링이 중요하다.
> 그러므로 머신러닝 시스템에서 모니터링 하고 싶은 내용이 무엇인지 고민하고 선정 할 필요가 있다. 

#### 7 다른 ML관련 부채 
#### 7.1 데이터 테스팅 부채
잘 작동하는ML시스템에서 코드를 데이터가 대체하게 된다면 테스팅을 위한 어느 정도 양의 input 데이터가 필요하다. 
정교한 테스트들이 input distribution의 분포 변화를 감지할때, 기본적인 sanity check이 유용하다. 

#### 7.2 재현성 부채 
과학자들의 입장에서는 같은 실험을 반복해서 비슷한 결과를 도출하는 것이 중요하다. 하지만 현실 
시스템에서 재현성을 디자인 하는 일은 확률적 알고리즘, non-determinism inherent in parellel learning, 
초기 상태에 대한 의존성 그리고 외부와의 교류로 인해서 어려워진다.

#### 7.3 프로세스 관리 부채 
위에서 언급한 부채들은 대부분 하나의 모델을 유지보수하는 관점에서 비용을 살펴보았다. 하지만 성숙한 
시스템은 대부분 수 많은 모델이 동시에 작동한다. 이러한 상황은 여러 유사한 모델들에서 동일하게 사용되는 
중요한 문제들을 광범위하게 발생시킨다. 여러 유사한 모델의 여러가지 configuration을 안정적이게 자동으로
업데이트하는 문제, 각자 다른 비즈니스 우선순위를 가진 모델에 자원을 분배하고 관리하는 문제 그리고 
프로덕션 파이프라인에서 데이터의 흐름상의 blockage를 시각화하고 감지하는 등의 문제들을 발생 시킨다. 
이러한 프로덕션 간 피해 복구에 도움이 될 수 있는 툴 개발도 중요하다. 꼭 피해야 하는 중요한 시스템 
레벨의 문제는 공통적이면서 수동적인 프로세스를 방지하는 것이다. 

#### 7.4 문화적 부채
가끔 리서치와 엔지니어링의 경계가 뚜렷한 상황들이 있다. 하지만, 이러한 거리감은 장기적인 시스템 건강 
관점에서 비생산적으로 여겨진다. 팀 차원에서 기능 위임(delegation of features), 복잡성 감소, 재현성 증가, 
안정성 증가에 대한 보상이 필요하다. 이러한 속성들을 모델의 정확도를 향상시키는 일과 동일한 수준에서
모니터링 되어야한다. 경험상 이런 상황은 ML 리서치와 엔지니어링 모두 강한 팀에서 발생한다. 
 
--- 
#### Conclusions : 부채 측정 및 청산 
기술 부채는 유용한 은유이지만 아쉽게도 정확하고 추적가능한 metric을 제공하지는 못한다. 
우리는 시스템 내에서 기술 부채를 어떻게 측정하고 총 비용을 어떻게 계산해야하는가?
하나의 팀이 빠른 작업은 부채가 적다거나 good practice라는 것을 
증명하기위한 충분한 증거가 되지 않는다. 왜냐하면 부채의 총 비용은 시간이 지나야지 드러나기 때문이다.
더 나아가, 빠른 작업은 부채를 만들어낸다. 다음은 부채를 방지하기 위해 던질만한 유용한 질문들이다 : 
* 새로운 알고리즘적 접근이 얼마나 쉽게 실제 규모의 테스트를 할 수 있는가? 
* 모든 data의존성의 transitive closure(이행적 폐쇄)가 무엇인가?
* 새로운 변화의 영향이 얼마나 정확하게 측정 될 수 있는가?
* 한 모델이나 시그널을 발전시키는 것이 다른 것들을 퇴화시키는가?
* 얼마나 빠르게 팀의 새로운 멤버가 팀 작업속도에 따라갈 수 있는가? 

발전된 추상화, 테스트 방법론 그리고 디자인 패턴을 지속적으로 만들어 낼 수 있길 바란다. 
리서처와 엔지니어 모두 고려해야 할 기술 부채 문제에 대해서 다루어 봤다. 
기술 부채를 청산해 나가는 과정은 해당 팀 문화에 특화된 노력이 필요하다.
이러한 노력에 대해서 인지하고 우선순위로 두고 또 보상하는 문화가 장기적인 ML 팀을
만들어 내는데 기여 할 것이다.  

> ML 시스템에서 "에이 별 문제 아니네!" 싶은거 싹 다 부채임






